{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = './horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=3, shuffle=False, num_workers=1)  \n",
    "\n",
    "validation_data_path = './horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=3, shuffle=False, num_workers=1)  \n",
    "\n",
    "\n",
    "trainList = list()\n",
    "validList = list()\n",
    "trainLabelList = list()\n",
    "validLabelList = list()\n",
    "\n",
    "for i, data in enumerate(trainloader):\n",
    "    # inputs is the image\n",
    "    # labels is the class of the image\n",
    "    inputs, labels = data\n",
    "\n",
    "\n",
    "    # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "\n",
    "    batch_size = inputs.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "    # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "    # change inputs to matrix 10000*batch_size\n",
    "    for bat_idx in range(batch_size):\n",
    "\n",
    "        targMat = inputs[bat_idx][0]\n",
    "\n",
    "        colVec = np.reshape(targMat, (np.product(targMat.shape), 1), 'F')\n",
    "\n",
    "        if(bat_idx == 0):\n",
    "            batMat = colVec\n",
    "        else:\n",
    "            batMat = np.concatenate((batMat, colVec), axis = 1)         \n",
    "\n",
    "    # Add ones because of the value b in coefficient\n",
    "    ones = np.ones((1, batch_size), dtype = int)\n",
    "    batMat = np.concatenate((batMat, ones))\n",
    "    trainList.append(batMat)\n",
    "    trainLabelList.append(labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load validation images of the batch size for every iteration\n",
    "for i, data in enumerate(valloader):\n",
    "\n",
    "    # inputs is the image\n",
    "    # labels is the class of the image\n",
    "    inputs, labels = data\n",
    "\n",
    "    # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "     # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "\n",
    "    batch_size = inputs.shape[0]\n",
    "\n",
    "\n",
    "    # Change Inputs to matrix 10000*batch_size\n",
    "\n",
    "    for bat_idx in range(batch_size):\n",
    "        targMat = inputs[bat_idx][0]\n",
    "        colVec = np.reshape(targMat, (np.product(targMat.shape), 1), 'F')\n",
    "\n",
    "        if(bat_idx == 0):\n",
    "            batMat = colVec\n",
    "        else:\n",
    "            batMat = np.concatenate((batMat,colVec), axis = 1)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    # Add ones because of the value b in coefficient\n",
    "    ones = np.ones((1, batch_size), dtype = int)\n",
    "    batMat = np.concatenate((batMat, ones))\n",
    "    validList.append(batMat)\n",
    "    validLabelList.append(labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0 , lrnCor :  500 valCor :  128 elapsed time :  0.35717129707336426\n",
      "epoch :  1 , lrnCor :  527 valCor :  128 elapsed time :  0.3743762969970703\n",
      "epoch :  2 , lrnCor :  529 valCor :  128 elapsed time :  0.3772141933441162\n",
      "epoch :  3 , lrnCor :  529 valCor :  128 elapsed time :  0.3679769039154053\n",
      "epoch :  4 , lrnCor :  555 valCor :  129 elapsed time :  0.3654351234436035\n",
      "epoch :  5 , lrnCor :  562 valCor :  135 elapsed time :  0.36958789825439453\n",
      "epoch :  6 , lrnCor :  569 valCor :  140 elapsed time :  0.36948513984680176\n",
      "epoch :  7 , lrnCor :  577 valCor :  149 elapsed time :  0.36916184425354004\n",
      "epoch :  8 , lrnCor :  577 valCor :  160 elapsed time :  0.41475605964660645\n",
      "epoch :  9 , lrnCor :  584 valCor :  176 elapsed time :  0.41450977325439453\n",
      "epoch :  10 , lrnCor :  602 valCor :  183 elapsed time :  0.4842796325683594\n",
      "epoch :  11 , lrnCor :  626 valCor :  189 elapsed time :  0.5107169151306152\n",
      "epoch :  12 , lrnCor :  638 valCor :  199 elapsed time :  0.5565619468688965\n",
      "epoch :  13 , lrnCor :  650 valCor :  204 elapsed time :  0.7462489604949951\n",
      "epoch :  14 , lrnCor :  663 valCor :  210 elapsed time :  0.49753332138061523\n",
      "epoch :  15 , lrnCor :  671 valCor :  214 elapsed time :  0.5246329307556152\n",
      "epoch :  16 , lrnCor :  677 valCor :  219 elapsed time :  0.399946928024292\n",
      "epoch :  17 , lrnCor :  684 valCor :  220 elapsed time :  0.39373016357421875\n",
      "epoch :  18 , lrnCor :  687 valCor :  222 elapsed time :  0.3769190311431885\n",
      "epoch :  19 , lrnCor :  690 valCor :  222 elapsed time :  0.434999942779541\n",
      "epoch :  20 , lrnCor :  699 valCor :  222 elapsed time :  0.44413208961486816\n",
      "epoch :  21 , lrnCor :  702 valCor :  222 elapsed time :  0.46241307258605957\n",
      "epoch :  22 , lrnCor :  707 valCor :  224 elapsed time :  0.4647948741912842\n",
      "epoch :  23 , lrnCor :  710 valCor :  223 elapsed time :  0.4531667232513428\n",
      "epoch :  24 , lrnCor :  713 valCor :  222 elapsed time :  0.4990520477294922\n",
      "epoch :  25 , lrnCor :  716 valCor :  223 elapsed time :  0.5147490501403809\n",
      "epoch :  26 , lrnCor :  723 valCor :  224 elapsed time :  0.5462079048156738\n",
      "epoch :  27 , lrnCor :  726 valCor :  226 elapsed time :  0.46569180488586426\n",
      "epoch :  28 , lrnCor :  724 valCor :  225 elapsed time :  0.4653949737548828\n",
      "epoch :  29 , lrnCor :  726 valCor :  225 elapsed time :  0.44942426681518555\n",
      "epoch :  30 , lrnCor :  731 valCor :  225 elapsed time :  0.44687414169311523\n",
      "epoch :  31 , lrnCor :  733 valCor :  225 elapsed time :  0.46636176109313965\n",
      "epoch :  32 , lrnCor :  733 valCor :  226 elapsed time :  0.45897698402404785\n",
      "epoch :  33 , lrnCor :  732 valCor :  226 elapsed time :  0.5306129455566406\n",
      "epoch :  34 , lrnCor :  733 valCor :  226 elapsed time :  0.6399710178375244\n",
      "epoch :  35 , lrnCor :  737 valCor :  226 elapsed time :  0.4557490348815918\n",
      "epoch :  36 , lrnCor :  739 valCor :  226 elapsed time :  0.5544309616088867\n",
      "epoch :  37 , lrnCor :  742 valCor :  226 elapsed time :  0.4988579750061035\n",
      "epoch :  38 , lrnCor :  744 valCor :  227 elapsed time :  0.3780171871185303\n",
      "epoch :  39 , lrnCor :  745 valCor :  227 elapsed time :  0.49326419830322266\n",
      "epoch :  40 , lrnCor :  746 valCor :  227 elapsed time :  0.5970277786254883\n",
      "epoch :  41 , lrnCor :  748 valCor :  226 elapsed time :  0.48265600204467773\n",
      "epoch :  42 , lrnCor :  751 valCor :  226 elapsed time :  0.5475571155548096\n",
      "epoch :  43 , lrnCor :  752 valCor :  226 elapsed time :  0.4588472843170166\n",
      "epoch :  44 , lrnCor :  751 valCor :  225 elapsed time :  0.4569730758666992\n",
      "epoch :  45 , lrnCor :  751 valCor :  225 elapsed time :  0.4413890838623047\n",
      "epoch :  46 , lrnCor :  751 valCor :  225 elapsed time :  0.4449450969696045\n",
      "epoch :  47 , lrnCor :  752 valCor :  224 elapsed time :  0.4697139263153076\n",
      "epoch :  48 , lrnCor :  754 valCor :  224 elapsed time :  0.4548218250274658\n",
      "epoch :  49 , lrnCor :  758 valCor :  224 elapsed time :  0.4348311424255371\n",
      "epoch :  50 , lrnCor :  758 valCor :  223 elapsed time :  0.3713078498840332\n",
      "epoch :  51 , lrnCor :  758 valCor :  223 elapsed time :  0.3711509704589844\n",
      "epoch :  52 , lrnCor :  759 valCor :  223 elapsed time :  0.4123990535736084\n",
      "epoch :  53 , lrnCor :  762 valCor :  223 elapsed time :  0.5613851547241211\n",
      "epoch :  54 , lrnCor :  764 valCor :  223 elapsed time :  0.5360729694366455\n",
      "epoch :  55 , lrnCor :  765 valCor :  223 elapsed time :  0.5409228801727295\n",
      "epoch :  56 , lrnCor :  764 valCor :  222 elapsed time :  0.487537145614624\n",
      "epoch :  57 , lrnCor :  766 valCor :  222 elapsed time :  0.4559648036956787\n",
      "epoch :  58 , lrnCor :  767 valCor :  222 elapsed time :  0.4458439350128174\n",
      "epoch :  59 , lrnCor :  768 valCor :  223 elapsed time :  0.4160420894622803\n",
      "epoch :  60 , lrnCor :  769 valCor :  223 elapsed time :  0.3686389923095703\n",
      "epoch :  61 , lrnCor :  770 valCor :  223 elapsed time :  0.37224507331848145\n",
      "epoch :  62 , lrnCor :  772 valCor :  222 elapsed time :  0.36316585540771484\n",
      "epoch :  63 , lrnCor :  773 valCor :  223 elapsed time :  0.3707468509674072\n",
      "epoch :  64 , lrnCor :  773 valCor :  223 elapsed time :  0.36931324005126953\n",
      "epoch :  65 , lrnCor :  774 valCor :  223 elapsed time :  0.3700888156890869\n",
      "epoch :  66 , lrnCor :  774 valCor :  222 elapsed time :  0.3845100402832031\n",
      "epoch :  67 , lrnCor :  775 valCor :  221 elapsed time :  0.3729252815246582\n",
      "epoch :  68 , lrnCor :  775 valCor :  221 elapsed time :  0.36856579780578613\n",
      "epoch :  69 , lrnCor :  776 valCor :  221 elapsed time :  0.37337207794189453\n",
      "epoch :  70 , lrnCor :  776 valCor :  221 elapsed time :  0.4328000545501709\n",
      "epoch :  71 , lrnCor :  777 valCor :  221 elapsed time :  0.4430420398712158\n",
      "epoch :  72 , lrnCor :  778 valCor :  221 elapsed time :  0.4484400749206543\n",
      "epoch :  73 , lrnCor :  778 valCor :  221 elapsed time :  0.4000539779663086\n",
      "epoch :  74 , lrnCor :  780 valCor :  221 elapsed time :  0.42178893089294434\n",
      "epoch :  75 , lrnCor :  781 valCor :  222 elapsed time :  0.42772912979125977\n",
      "epoch :  76 , lrnCor :  781 valCor :  222 elapsed time :  0.40604591369628906\n",
      "epoch :  77 , lrnCor :  781 valCor :  222 elapsed time :  0.3871040344238281\n",
      "epoch :  78 , lrnCor :  782 valCor :  222 elapsed time :  0.4276740550994873\n",
      "epoch :  79 , lrnCor :  782 valCor :  222 elapsed time :  0.3842501640319824\n",
      "epoch :  80 , lrnCor :  782 valCor :  222 elapsed time :  0.37096691131591797\n",
      "epoch :  81 , lrnCor :  783 valCor :  223 elapsed time :  0.3811798095703125\n",
      "epoch :  82 , lrnCor :  783 valCor :  223 elapsed time :  0.38130903244018555\n",
      "epoch :  83 , lrnCor :  784 valCor :  223 elapsed time :  0.3789350986480713\n",
      "epoch :  84 , lrnCor :  784 valCor :  223 elapsed time :  0.41744184494018555\n",
      "epoch :  85 , lrnCor :  785 valCor :  223 elapsed time :  0.4145927429199219\n",
      "epoch :  86 , lrnCor :  785 valCor :  223 elapsed time :  0.3841228485107422\n",
      "epoch :  87 , lrnCor :  785 valCor :  223 elapsed time :  0.3691997528076172\n",
      "epoch :  88 , lrnCor :  785 valCor :  223 elapsed time :  0.36658477783203125\n",
      "epoch :  89 , lrnCor :  784 valCor :  223 elapsed time :  0.4560530185699463\n",
      "epoch :  90 , lrnCor :  784 valCor :  223 elapsed time :  0.46272897720336914\n",
      "epoch :  91 , lrnCor :  785 valCor :  223 elapsed time :  0.4549379348754883\n",
      "epoch :  92 , lrnCor :  785 valCor :  223 elapsed time :  0.37810683250427246\n",
      "epoch :  93 , lrnCor :  785 valCor :  223 elapsed time :  0.3717329502105713\n",
      "epoch :  94 , lrnCor :  785 valCor :  223 elapsed time :  0.3704359531402588\n",
      "epoch :  95 , lrnCor :  785 valCor :  223 elapsed time :  0.37389206886291504\n",
      "epoch :  96 , lrnCor :  786 valCor :  223 elapsed time :  0.37482118606567383\n",
      "epoch :  97 , lrnCor :  785 valCor :  223 elapsed time :  0.37485599517822266\n",
      "epoch :  98 , lrnCor :  785 valCor :  223 elapsed time :  0.36995983123779297\n",
      "epoch :  99 , lrnCor :  785 valCor :  223 elapsed time :  0.3698079586029053\n",
      "epoch :  100 , lrnCor :  785 valCor :  224 elapsed time :  0.36598706245422363\n",
      "epoch :  101 , lrnCor :  784 valCor :  224 elapsed time :  0.47005510330200195\n",
      "epoch :  102 , lrnCor :  786 valCor :  224 elapsed time :  0.45514702796936035\n",
      "epoch :  103 , lrnCor :  786 valCor :  224 elapsed time :  0.4490530490875244\n",
      "epoch :  104 , lrnCor :  786 valCor :  224 elapsed time :  0.4028480052947998\n",
      "epoch :  105 , lrnCor :  786 valCor :  224 elapsed time :  0.37572669982910156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  106 , lrnCor :  786 valCor :  224 elapsed time :  0.3703773021697998\n",
      "epoch :  107 , lrnCor :  787 valCor :  224 elapsed time :  0.3635139465332031\n",
      "epoch :  108 , lrnCor :  788 valCor :  224 elapsed time :  0.3636598587036133\n",
      "epoch :  109 , lrnCor :  788 valCor :  224 elapsed time :  0.356032133102417\n",
      "epoch :  110 , lrnCor :  788 valCor :  224 elapsed time :  0.3577086925506592\n",
      "epoch :  111 , lrnCor :  789 valCor :  224 elapsed time :  0.3592996597290039\n",
      "epoch :  112 , lrnCor :  789 valCor :  224 elapsed time :  0.3539581298828125\n",
      "epoch :  113 , lrnCor :  789 valCor :  224 elapsed time :  0.3725709915161133\n",
      "epoch :  114 , lrnCor :  789 valCor :  224 elapsed time :  0.3638613224029541\n",
      "epoch :  115 , lrnCor :  789 valCor :  223 elapsed time :  0.3621668815612793\n",
      "epoch :  116 , lrnCor :  790 valCor :  223 elapsed time :  0.36931300163269043\n",
      "epoch :  117 , lrnCor :  790 valCor :  223 elapsed time :  0.36614513397216797\n",
      "epoch :  118 , lrnCor :  790 valCor :  223 elapsed time :  0.37241196632385254\n",
      "epoch :  119 , lrnCor :  790 valCor :  223 elapsed time :  0.41861891746520996\n",
      "epoch :  120 , lrnCor :  791 valCor :  223 elapsed time :  0.44310998916625977\n",
      "epoch :  121 , lrnCor :  791 valCor :  223 elapsed time :  0.45268702507019043\n",
      "epoch :  122 , lrnCor :  790 valCor :  223 elapsed time :  0.38912010192871094\n",
      "epoch :  123 , lrnCor :  791 valCor :  223 elapsed time :  0.36605286598205566\n",
      "epoch :  124 , lrnCor :  791 valCor :  222 elapsed time :  0.36396312713623047\n",
      "epoch :  125 , lrnCor :  792 valCor :  222 elapsed time :  0.38825082778930664\n",
      "epoch :  126 , lrnCor :  792 valCor :  222 elapsed time :  0.36663198471069336\n",
      "epoch :  127 , lrnCor :  794 valCor :  222 elapsed time :  0.36524534225463867\n",
      "epoch :  128 , lrnCor :  795 valCor :  222 elapsed time :  0.3687412738800049\n",
      "epoch :  129 , lrnCor :  794 valCor :  223 elapsed time :  0.3667948246002197\n",
      "epoch :  130 , lrnCor :  795 valCor :  223 elapsed time :  0.3705737590789795\n",
      "epoch :  131 , lrnCor :  795 valCor :  223 elapsed time :  0.35881590843200684\n",
      "epoch :  132 , lrnCor :  796 valCor :  223 elapsed time :  0.3601350784301758\n",
      "epoch :  133 , lrnCor :  796 valCor :  223 elapsed time :  0.36977720260620117\n",
      "epoch :  134 , lrnCor :  796 valCor :  223 elapsed time :  0.36505818367004395\n",
      "epoch :  135 , lrnCor :  797 valCor :  223 elapsed time :  0.3734560012817383\n",
      "epoch :  136 , lrnCor :  797 valCor :  223 elapsed time :  0.3913540840148926\n",
      "epoch :  137 , lrnCor :  797 valCor :  223 elapsed time :  0.36454129219055176\n",
      "epoch :  138 , lrnCor :  797 valCor :  223 elapsed time :  0.36629605293273926\n",
      "epoch :  139 , lrnCor :  798 valCor :  223 elapsed time :  0.3701188564300537\n",
      "epoch :  140 , lrnCor :  800 valCor :  223 elapsed time :  0.36219120025634766\n",
      "epoch :  141 , lrnCor :  799 valCor :  223 elapsed time :  0.36768507957458496\n",
      "epoch :  142 , lrnCor :  799 valCor :  223 elapsed time :  0.3695650100708008\n",
      "epoch :  143 , lrnCor :  799 valCor :  223 elapsed time :  0.36635375022888184\n",
      "epoch :  144 , lrnCor :  799 valCor :  223 elapsed time :  0.36518192291259766\n",
      "epoch :  145 , lrnCor :  800 valCor :  223 elapsed time :  0.3659861087799072\n",
      "epoch :  146 , lrnCor :  800 valCor :  223 elapsed time :  0.36266493797302246\n",
      "epoch :  147 , lrnCor :  801 valCor :  223 elapsed time :  0.3632547855377197\n",
      "epoch :  148 , lrnCor :  801 valCor :  223 elapsed time :  0.3658568859100342\n",
      "epoch :  149 , lrnCor :  802 valCor :  223 elapsed time :  0.39449501037597656\n",
      "epoch :  150 , lrnCor :  804 valCor :  223 elapsed time :  0.3672921657562256\n",
      "epoch :  151 , lrnCor :  804 valCor :  223 elapsed time :  0.36095213890075684\n",
      "epoch :  152 , lrnCor :  805 valCor :  223 elapsed time :  0.37699103355407715\n",
      "epoch :  153 , lrnCor :  805 valCor :  223 elapsed time :  0.3636341094970703\n",
      "epoch :  154 , lrnCor :  805 valCor :  223 elapsed time :  0.3636929988861084\n",
      "epoch :  155 , lrnCor :  806 valCor :  223 elapsed time :  0.36790895462036133\n",
      "epoch :  156 , lrnCor :  806 valCor :  223 elapsed time :  0.364041805267334\n",
      "epoch :  157 , lrnCor :  806 valCor :  223 elapsed time :  0.45067906379699707\n",
      "epoch :  158 , lrnCor :  806 valCor :  223 elapsed time :  0.4705469608306885\n",
      "epoch :  159 , lrnCor :  806 valCor :  223 elapsed time :  0.45274806022644043\n",
      "epoch :  160 , lrnCor :  806 valCor :  223 elapsed time :  0.47095489501953125\n",
      "epoch :  161 , lrnCor :  806 valCor :  223 elapsed time :  0.4522829055786133\n",
      "epoch :  162 , lrnCor :  806 valCor :  223 elapsed time :  0.4406120777130127\n",
      "epoch :  163 , lrnCor :  806 valCor :  223 elapsed time :  0.43998122215270996\n",
      "epoch :  164 , lrnCor :  806 valCor :  223 elapsed time :  0.44376277923583984\n",
      "epoch :  165 , lrnCor :  806 valCor :  223 elapsed time :  0.49593305587768555\n",
      "epoch :  166 , lrnCor :  807 valCor :  223 elapsed time :  0.6830201148986816\n",
      "epoch :  167 , lrnCor :  808 valCor :  223 elapsed time :  0.5240399837493896\n",
      "epoch :  168 , lrnCor :  809 valCor :  223 elapsed time :  0.5003101825714111\n",
      "epoch :  169 , lrnCor :  809 valCor :  223 elapsed time :  0.5438389778137207\n",
      "epoch :  170 , lrnCor :  809 valCor :  223 elapsed time :  0.37494492530822754\n",
      "epoch :  171 , lrnCor :  809 valCor :  223 elapsed time :  0.41263699531555176\n",
      "epoch :  172 , lrnCor :  809 valCor :  223 elapsed time :  0.3685638904571533\n",
      "epoch :  173 , lrnCor :  809 valCor :  223 elapsed time :  0.37120509147644043\n",
      "epoch :  174 , lrnCor :  810 valCor :  223 elapsed time :  0.3711066246032715\n",
      "epoch :  175 , lrnCor :  811 valCor :  223 elapsed time :  0.4908759593963623\n",
      "epoch :  176 , lrnCor :  811 valCor :  223 elapsed time :  0.37342000007629395\n",
      "epoch :  177 , lrnCor :  812 valCor :  223 elapsed time :  0.5362739562988281\n",
      "epoch :  178 , lrnCor :  813 valCor :  223 elapsed time :  0.44495224952697754\n",
      "epoch :  179 , lrnCor :  814 valCor :  223 elapsed time :  0.5480999946594238\n",
      "epoch :  180 , lrnCor :  814 valCor :  223 elapsed time :  0.5613360404968262\n",
      "epoch :  181 , lrnCor :  814 valCor :  223 elapsed time :  0.5313618183135986\n",
      "epoch :  182 , lrnCor :  816 valCor :  223 elapsed time :  0.5395371913909912\n",
      "epoch :  183 , lrnCor :  816 valCor :  223 elapsed time :  0.5517938137054443\n",
      "epoch :  184 , lrnCor :  817 valCor :  223 elapsed time :  0.6283509731292725\n",
      "epoch :  185 , lrnCor :  818 valCor :  223 elapsed time :  0.3758049011230469\n",
      "epoch :  186 , lrnCor :  818 valCor :  223 elapsed time :  0.41308069229125977\n",
      "epoch :  187 , lrnCor :  818 valCor :  223 elapsed time :  0.3659660816192627\n",
      "epoch :  188 , lrnCor :  818 valCor :  223 elapsed time :  0.3676419258117676\n",
      "epoch :  189 , lrnCor :  818 valCor :  223 elapsed time :  0.3836650848388672\n",
      "epoch :  190 , lrnCor :  817 valCor :  223 elapsed time :  0.3921198844909668\n",
      "epoch :  191 , lrnCor :  818 valCor :  223 elapsed time :  0.4665980339050293\n",
      "epoch :  192 , lrnCor :  818 valCor :  223 elapsed time :  0.5710330009460449\n",
      "epoch :  193 , lrnCor :  819 valCor :  223 elapsed time :  0.5731561183929443\n",
      "epoch :  194 , lrnCor :  819 valCor :  223 elapsed time :  0.5653650760650635\n",
      "epoch :  195 , lrnCor :  819 valCor :  223 elapsed time :  0.5838232040405273\n",
      "epoch :  196 , lrnCor :  820 valCor :  223 elapsed time :  0.3855888843536377\n",
      "epoch :  197 , lrnCor :  821 valCor :  223 elapsed time :  0.40955185890197754\n",
      "epoch :  198 , lrnCor :  821 valCor :  223 elapsed time :  0.4010429382324219\n",
      "epoch :  199 , lrnCor :  822 valCor :  223 elapsed time :  0.3761627674102783\n",
      "epoch :  200 , lrnCor :  822 valCor :  223 elapsed time :  0.423961877822876\n",
      "epoch :  201 , lrnCor :  824 valCor :  223 elapsed time :  0.38103199005126953\n",
      "epoch :  202 , lrnCor :  824 valCor :  223 elapsed time :  0.3849799633026123\n",
      "epoch :  203 , lrnCor :  824 valCor :  223 elapsed time :  0.5640177726745605\n",
      "epoch :  204 , lrnCor :  824 valCor :  223 elapsed time :  0.40599584579467773\n",
      "epoch :  205 , lrnCor :  824 valCor :  223 elapsed time :  0.3861992359161377\n",
      "epoch :  206 , lrnCor :  824 valCor :  223 elapsed time :  0.39368605613708496\n",
      "epoch :  207 , lrnCor :  824 valCor :  223 elapsed time :  0.4124948978424072\n",
      "epoch :  208 , lrnCor :  824 valCor :  223 elapsed time :  0.42594289779663086\n",
      "epoch :  209 , lrnCor :  824 valCor :  223 elapsed time :  0.3992340564727783\n",
      "epoch :  210 , lrnCor :  824 valCor :  223 elapsed time :  0.6942260265350342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  211 , lrnCor :  823 valCor :  223 elapsed time :  0.49494409561157227\n",
      "epoch :  212 , lrnCor :  823 valCor :  223 elapsed time :  0.4318959712982178\n",
      "epoch :  213 , lrnCor :  822 valCor :  223 elapsed time :  0.40607523918151855\n",
      "epoch :  214 , lrnCor :  822 valCor :  223 elapsed time :  0.5659358501434326\n",
      "epoch :  215 , lrnCor :  822 valCor :  223 elapsed time :  0.4045379161834717\n",
      "epoch :  216 , lrnCor :  822 valCor :  223 elapsed time :  0.4613502025604248\n",
      "epoch :  217 , lrnCor :  823 valCor :  223 elapsed time :  0.39592766761779785\n",
      "epoch :  218 , lrnCor :  823 valCor :  223 elapsed time :  0.40319108963012695\n",
      "epoch :  219 , lrnCor :  823 valCor :  223 elapsed time :  0.3912692070007324\n",
      "epoch :  220 , lrnCor :  823 valCor :  223 elapsed time :  0.37357592582702637\n",
      "epoch :  221 , lrnCor :  824 valCor :  223 elapsed time :  0.3631610870361328\n",
      "epoch :  222 , lrnCor :  824 valCor :  223 elapsed time :  0.3668041229248047\n",
      "epoch :  223 , lrnCor :  824 valCor :  223 elapsed time :  0.36554479598999023\n",
      "epoch :  224 , lrnCor :  824 valCor :  223 elapsed time :  0.3650531768798828\n",
      "epoch :  225 , lrnCor :  825 valCor :  223 elapsed time :  0.48586297035217285\n",
      "epoch :  226 , lrnCor :  826 valCor :  223 elapsed time :  0.3800480365753174\n",
      "epoch :  227 , lrnCor :  826 valCor :  223 elapsed time :  0.45578885078430176\n",
      "epoch :  228 , lrnCor :  826 valCor :  222 elapsed time :  0.40210509300231934\n",
      "epoch :  229 , lrnCor :  826 valCor :  222 elapsed time :  0.3954920768737793\n",
      "epoch :  230 , lrnCor :  825 valCor :  222 elapsed time :  0.38677406311035156\n",
      "epoch :  231 , lrnCor :  825 valCor :  222 elapsed time :  0.4027128219604492\n",
      "epoch :  232 , lrnCor :  826 valCor :  222 elapsed time :  0.37406015396118164\n",
      "epoch :  233 , lrnCor :  826 valCor :  222 elapsed time :  0.3706378936767578\n",
      "epoch :  234 , lrnCor :  827 valCor :  222 elapsed time :  0.3692638874053955\n",
      "epoch :  235 , lrnCor :  827 valCor :  222 elapsed time :  0.36757779121398926\n",
      "epoch :  236 , lrnCor :  826 valCor :  222 elapsed time :  0.36846113204956055\n",
      "epoch :  237 , lrnCor :  826 valCor :  222 elapsed time :  0.49854612350463867\n",
      "epoch :  238 , lrnCor :  826 valCor :  222 elapsed time :  0.39699816703796387\n",
      "epoch :  239 , lrnCor :  826 valCor :  222 elapsed time :  0.41599011421203613\n",
      "epoch :  240 , lrnCor :  826 valCor :  222 elapsed time :  0.36481595039367676\n",
      "epoch :  241 , lrnCor :  826 valCor :  222 elapsed time :  0.3659079074859619\n",
      "epoch :  242 , lrnCor :  826 valCor :  222 elapsed time :  0.3691689968109131\n",
      "epoch :  243 , lrnCor :  827 valCor :  222 elapsed time :  0.3673839569091797\n",
      "epoch :  244 , lrnCor :  827 valCor :  222 elapsed time :  0.3720240592956543\n",
      "epoch :  245 , lrnCor :  827 valCor :  222 elapsed time :  0.3691749572753906\n",
      "epoch :  246 , lrnCor :  827 valCor :  222 elapsed time :  0.36876797676086426\n",
      "epoch :  247 , lrnCor :  827 valCor :  222 elapsed time :  0.3676450252532959\n",
      "epoch :  248 , lrnCor :  827 valCor :  222 elapsed time :  0.3685898780822754\n",
      "epoch :  249 , lrnCor :  827 valCor :  222 elapsed time :  0.3693532943725586\n",
      "epoch :  250 , lrnCor :  827 valCor :  222 elapsed time :  0.3684048652648926\n",
      "epoch :  251 , lrnCor :  827 valCor :  222 elapsed time :  0.37030696868896484\n",
      "epoch :  252 , lrnCor :  827 valCor :  222 elapsed time :  0.3662562370300293\n",
      "epoch :  253 , lrnCor :  827 valCor :  222 elapsed time :  0.37026000022888184\n",
      "epoch :  254 , lrnCor :  828 valCor :  222 elapsed time :  0.37669897079467773\n",
      "epoch :  255 , lrnCor :  828 valCor :  222 elapsed time :  0.36869025230407715\n",
      "epoch :  256 , lrnCor :  828 valCor :  222 elapsed time :  0.3723561763763428\n",
      "epoch :  257 , lrnCor :  828 valCor :  222 elapsed time :  0.3761119842529297\n",
      "epoch :  258 , lrnCor :  828 valCor :  222 elapsed time :  0.3683280944824219\n",
      "epoch :  259 , lrnCor :  828 valCor :  222 elapsed time :  0.3749208450317383\n",
      "epoch :  260 , lrnCor :  829 valCor :  222 elapsed time :  0.36714887619018555\n",
      "epoch :  261 , lrnCor :  829 valCor :  222 elapsed time :  0.3707892894744873\n",
      "epoch :  262 , lrnCor :  829 valCor :  222 elapsed time :  0.37994980812072754\n",
      "epoch :  263 , lrnCor :  830 valCor :  222 elapsed time :  0.3700859546661377\n",
      "epoch :  264 , lrnCor :  829 valCor :  222 elapsed time :  0.3647618293762207\n",
      "epoch :  265 , lrnCor :  829 valCor :  222 elapsed time :  0.4018592834472656\n",
      "epoch :  266 , lrnCor :  829 valCor :  222 elapsed time :  0.5841658115386963\n",
      "epoch :  267 , lrnCor :  829 valCor :  222 elapsed time :  0.46611690521240234\n",
      "epoch :  268 , lrnCor :  829 valCor :  222 elapsed time :  0.4129452705383301\n",
      "epoch :  269 , lrnCor :  829 valCor :  222 elapsed time :  0.37295103073120117\n",
      "epoch :  270 , lrnCor :  829 valCor :  222 elapsed time :  0.3778078556060791\n",
      "epoch :  271 , lrnCor :  830 valCor :  222 elapsed time :  0.37080812454223633\n",
      "epoch :  272 , lrnCor :  830 valCor :  222 elapsed time :  0.3765242099761963\n",
      "epoch :  273 , lrnCor :  830 valCor :  222 elapsed time :  0.37493300437927246\n",
      "epoch :  274 , lrnCor :  830 valCor :  222 elapsed time :  0.5138170719146729\n",
      "epoch :  275 , lrnCor :  830 valCor :  222 elapsed time :  0.3717961311340332\n",
      "epoch :  276 , lrnCor :  830 valCor :  222 elapsed time :  0.4133760929107666\n",
      "epoch :  277 , lrnCor :  830 valCor :  222 elapsed time :  0.3716127872467041\n",
      "epoch :  278 , lrnCor :  830 valCor :  222 elapsed time :  0.3895847797393799\n",
      "epoch :  279 , lrnCor :  830 valCor :  222 elapsed time :  0.38059115409851074\n",
      "epoch :  280 , lrnCor :  830 valCor :  222 elapsed time :  0.3688352108001709\n",
      "epoch :  281 , lrnCor :  830 valCor :  222 elapsed time :  0.3708350658416748\n",
      "epoch :  282 , lrnCor :  830 valCor :  222 elapsed time :  0.36701202392578125\n",
      "epoch :  283 , lrnCor :  831 valCor :  222 elapsed time :  0.3717691898345947\n",
      "epoch :  284 , lrnCor :  831 valCor :  222 elapsed time :  0.3707249164581299\n",
      "epoch :  285 , lrnCor :  832 valCor :  222 elapsed time :  0.3745851516723633\n",
      "epoch :  286 , lrnCor :  833 valCor :  222 elapsed time :  0.4233436584472656\n",
      "epoch :  287 , lrnCor :  833 valCor :  222 elapsed time :  0.4036839008331299\n",
      "epoch :  288 , lrnCor :  833 valCor :  222 elapsed time :  0.4022860527038574\n",
      "epoch :  289 , lrnCor :  834 valCor :  222 elapsed time :  0.3714101314544678\n",
      "epoch :  290 , lrnCor :  834 valCor :  222 elapsed time :  0.3678913116455078\n",
      "epoch :  291 , lrnCor :  834 valCor :  222 elapsed time :  0.3691132068634033\n",
      "epoch :  292 , lrnCor :  835 valCor :  222 elapsed time :  0.37157678604125977\n",
      "epoch :  293 , lrnCor :  835 valCor :  222 elapsed time :  0.372081995010376\n",
      "epoch :  294 , lrnCor :  835 valCor :  222 elapsed time :  0.3745999336242676\n",
      "epoch :  295 , lrnCor :  836 valCor :  222 elapsed time :  0.37488222122192383\n",
      "epoch :  296 , lrnCor :  836 valCor :  222 elapsed time :  0.4721500873565674\n",
      "epoch :  297 , lrnCor :  836 valCor :  221 elapsed time :  0.3933680057525635\n",
      "epoch :  298 , lrnCor :  836 valCor :  221 elapsed time :  0.515434980392456\n",
      "epoch :  299 , lrnCor :  836 valCor :  221 elapsed time :  0.3749430179595947\n",
      "epoch :  300 , lrnCor :  836 valCor :  221 elapsed time :  0.40665698051452637\n",
      "epoch :  301 , lrnCor :  837 valCor :  221 elapsed time :  0.3724088668823242\n",
      "epoch :  302 , lrnCor :  837 valCor :  222 elapsed time :  0.39679384231567383\n",
      "epoch :  303 , lrnCor :  838 valCor :  222 elapsed time :  0.3706989288330078\n",
      "epoch :  304 , lrnCor :  838 valCor :  222 elapsed time :  0.37389492988586426\n",
      "epoch :  305 , lrnCor :  838 valCor :  222 elapsed time :  0.3707540035247803\n",
      "epoch :  306 , lrnCor :  838 valCor :  222 elapsed time :  0.37299680709838867\n",
      "epoch :  307 , lrnCor :  838 valCor :  223 elapsed time :  0.3746371269226074\n",
      "epoch :  308 , lrnCor :  838 valCor :  223 elapsed time :  0.3735320568084717\n",
      "epoch :  309 , lrnCor :  838 valCor :  223 elapsed time :  0.3775289058685303\n",
      "epoch :  310 , lrnCor :  838 valCor :  223 elapsed time :  0.3677558898925781\n",
      "epoch :  311 , lrnCor :  838 valCor :  223 elapsed time :  0.3748049736022949\n",
      "epoch :  312 , lrnCor :  838 valCor :  223 elapsed time :  0.36948108673095703\n",
      "epoch :  313 , lrnCor :  838 valCor :  223 elapsed time :  0.37527990341186523\n",
      "epoch :  314 , lrnCor :  839 valCor :  223 elapsed time :  0.36874985694885254\n",
      "epoch :  315 , lrnCor :  839 valCor :  223 elapsed time :  0.37247586250305176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  316 , lrnCor :  839 valCor :  223 elapsed time :  0.3709282875061035\n",
      "epoch :  317 , lrnCor :  839 valCor :  223 elapsed time :  0.36982202529907227\n",
      "epoch :  318 , lrnCor :  840 valCor :  223 elapsed time :  0.5654361248016357\n",
      "epoch :  319 , lrnCor :  840 valCor :  223 elapsed time :  0.5771589279174805\n",
      "epoch :  320 , lrnCor :  840 valCor :  223 elapsed time :  0.5305631160736084\n",
      "epoch :  321 , lrnCor :  840 valCor :  223 elapsed time :  0.5069568157196045\n",
      "epoch :  322 , lrnCor :  841 valCor :  223 elapsed time :  0.7410509586334229\n",
      "epoch :  323 , lrnCor :  841 valCor :  223 elapsed time :  0.8486320972442627\n",
      "epoch :  324 , lrnCor :  841 valCor :  223 elapsed time :  0.5887110233306885\n",
      "epoch :  325 , lrnCor :  841 valCor :  223 elapsed time :  0.789743185043335\n",
      "epoch :  326 , lrnCor :  842 valCor :  223 elapsed time :  0.61844801902771\n",
      "epoch :  327 , lrnCor :  841 valCor :  223 elapsed time :  0.6869511604309082\n",
      "epoch :  328 , lrnCor :  841 valCor :  223 elapsed time :  0.3952357769012451\n",
      "epoch :  329 , lrnCor :  841 valCor :  223 elapsed time :  0.40747690200805664\n",
      "epoch :  330 , lrnCor :  841 valCor :  223 elapsed time :  0.36748218536376953\n",
      "epoch :  331 , lrnCor :  841 valCor :  223 elapsed time :  0.3725452423095703\n",
      "epoch :  332 , lrnCor :  841 valCor :  223 elapsed time :  0.376039981842041\n",
      "epoch :  333 , lrnCor :  841 valCor :  223 elapsed time :  0.37076401710510254\n",
      "epoch :  334 , lrnCor :  841 valCor :  223 elapsed time :  0.37137699127197266\n",
      "epoch :  335 , lrnCor :  841 valCor :  223 elapsed time :  0.365170955657959\n",
      "epoch :  336 , lrnCor :  842 valCor :  223 elapsed time :  0.3654360771179199\n",
      "epoch :  337 , lrnCor :  842 valCor :  223 elapsed time :  0.3706040382385254\n",
      "epoch :  338 , lrnCor :  843 valCor :  223 elapsed time :  0.37168192863464355\n",
      "epoch :  339 , lrnCor :  843 valCor :  223 elapsed time :  0.37346887588500977\n",
      "epoch :  340 , lrnCor :  843 valCor :  223 elapsed time :  0.37035393714904785\n",
      "epoch :  341 , lrnCor :  843 valCor :  223 elapsed time :  0.37071681022644043\n",
      "epoch :  342 , lrnCor :  843 valCor :  223 elapsed time :  0.36804819107055664\n",
      "epoch :  343 , lrnCor :  843 valCor :  223 elapsed time :  0.3738858699798584\n",
      "epoch :  344 , lrnCor :  843 valCor :  223 elapsed time :  0.3800530433654785\n",
      "epoch :  345 , lrnCor :  843 valCor :  223 elapsed time :  0.3699188232421875\n",
      "epoch :  346 , lrnCor :  843 valCor :  223 elapsed time :  0.37749767303466797\n",
      "epoch :  347 , lrnCor :  844 valCor :  223 elapsed time :  0.40264177322387695\n",
      "epoch :  348 , lrnCor :  844 valCor :  223 elapsed time :  0.44619083404541016\n",
      "epoch :  349 , lrnCor :  844 valCor :  223 elapsed time :  0.3853738307952881\n",
      "epoch :  350 , lrnCor :  844 valCor :  223 elapsed time :  0.41066884994506836\n",
      "epoch :  351 , lrnCor :  844 valCor :  223 elapsed time :  0.3892862796783447\n",
      "epoch :  352 , lrnCor :  844 valCor :  223 elapsed time :  0.40968799591064453\n",
      "epoch :  353 , lrnCor :  844 valCor :  223 elapsed time :  0.38000917434692383\n",
      "epoch :  354 , lrnCor :  844 valCor :  223 elapsed time :  0.3809499740600586\n",
      "epoch :  355 , lrnCor :  844 valCor :  223 elapsed time :  0.3707258701324463\n",
      "epoch :  356 , lrnCor :  844 valCor :  223 elapsed time :  0.3798081874847412\n",
      "epoch :  357 , lrnCor :  845 valCor :  223 elapsed time :  0.3744497299194336\n",
      "epoch :  358 , lrnCor :  845 valCor :  223 elapsed time :  0.3719978332519531\n",
      "epoch :  359 , lrnCor :  845 valCor :  223 elapsed time :  0.37978291511535645\n",
      "epoch :  360 , lrnCor :  845 valCor :  223 elapsed time :  0.38169002532958984\n",
      "epoch :  361 , lrnCor :  845 valCor :  223 elapsed time :  0.37267398834228516\n",
      "epoch :  362 , lrnCor :  845 valCor :  223 elapsed time :  0.370772123336792\n",
      "epoch :  363 , lrnCor :  845 valCor :  223 elapsed time :  0.3727607727050781\n",
      "epoch :  364 , lrnCor :  845 valCor :  223 elapsed time :  0.3682689666748047\n",
      "epoch :  365 , lrnCor :  846 valCor :  223 elapsed time :  0.370358943939209\n",
      "epoch :  366 , lrnCor :  847 valCor :  223 elapsed time :  0.37084007263183594\n",
      "epoch :  367 , lrnCor :  847 valCor :  223 elapsed time :  0.4031369686126709\n",
      "epoch :  368 , lrnCor :  848 valCor :  223 elapsed time :  0.37334418296813965\n",
      "epoch :  369 , lrnCor :  849 valCor :  223 elapsed time :  0.37180209159851074\n",
      "epoch :  370 , lrnCor :  850 valCor :  223 elapsed time :  0.3733658790588379\n",
      "epoch :  371 , lrnCor :  850 valCor :  223 elapsed time :  0.3728048801422119\n",
      "epoch :  372 , lrnCor :  850 valCor :  223 elapsed time :  0.3733360767364502\n",
      "epoch :  373 , lrnCor :  850 valCor :  223 elapsed time :  0.37306809425354004\n",
      "epoch :  374 , lrnCor :  850 valCor :  223 elapsed time :  0.37469005584716797\n",
      "epoch :  375 , lrnCor :  850 valCor :  223 elapsed time :  0.3778998851776123\n",
      "epoch :  376 , lrnCor :  850 valCor :  223 elapsed time :  0.3658177852630615\n",
      "epoch :  377 , lrnCor :  850 valCor :  223 elapsed time :  0.3720419406890869\n",
      "epoch :  378 , lrnCor :  850 valCor :  223 elapsed time :  0.3726677894592285\n",
      "epoch :  379 , lrnCor :  851 valCor :  223 elapsed time :  0.3724479675292969\n",
      "epoch :  380 , lrnCor :  851 valCor :  223 elapsed time :  0.37183213233947754\n",
      "epoch :  381 , lrnCor :  851 valCor :  223 elapsed time :  0.367717981338501\n",
      "epoch :  382 , lrnCor :  851 valCor :  223 elapsed time :  0.37689900398254395\n",
      "epoch :  383 , lrnCor :  852 valCor :  223 elapsed time :  0.37493300437927246\n",
      "epoch :  384 , lrnCor :  852 valCor :  223 elapsed time :  0.37830400466918945\n",
      "epoch :  385 , lrnCor :  852 valCor :  223 elapsed time :  0.4150879383087158\n",
      "epoch :  386 , lrnCor :  852 valCor :  223 elapsed time :  0.41663479804992676\n",
      "epoch :  387 , lrnCor :  852 valCor :  223 elapsed time :  0.37679600715637207\n",
      "epoch :  388 , lrnCor :  852 valCor :  223 elapsed time :  0.3883209228515625\n",
      "epoch :  389 , lrnCor :  852 valCor :  223 elapsed time :  0.3757350444793701\n",
      "epoch :  390 , lrnCor :  852 valCor :  223 elapsed time :  0.387174129486084\n",
      "epoch :  391 , lrnCor :  853 valCor :  223 elapsed time :  0.39357614517211914\n",
      "epoch :  392 , lrnCor :  853 valCor :  223 elapsed time :  0.376971960067749\n",
      "epoch :  393 , lrnCor :  853 valCor :  223 elapsed time :  0.37284088134765625\n",
      "epoch :  394 , lrnCor :  853 valCor :  223 elapsed time :  0.37140798568725586\n",
      "epoch :  395 , lrnCor :  853 valCor :  223 elapsed time :  0.36835312843322754\n",
      "epoch :  396 , lrnCor :  853 valCor :  223 elapsed time :  0.3677330017089844\n",
      "epoch :  397 , lrnCor :  853 valCor :  223 elapsed time :  0.37253808975219727\n",
      "epoch :  398 , lrnCor :  853 valCor :  223 elapsed time :  0.37400078773498535\n",
      "epoch :  399 , lrnCor :  853 valCor :  223 elapsed time :  0.3790557384490967\n",
      "epoch :  400 , lrnCor :  853 valCor :  223 elapsed time :  0.4141538143157959\n",
      "epoch :  401 , lrnCor :  853 valCor :  223 elapsed time :  0.37595605850219727\n",
      "epoch :  402 , lrnCor :  853 valCor :  223 elapsed time :  0.3784189224243164\n",
      "epoch :  403 , lrnCor :  853 valCor :  223 elapsed time :  0.373319149017334\n",
      "epoch :  404 , lrnCor :  854 valCor :  223 elapsed time :  0.3735320568084717\n",
      "epoch :  405 , lrnCor :  854 valCor :  223 elapsed time :  0.3680100440979004\n",
      "epoch :  406 , lrnCor :  854 valCor :  223 elapsed time :  0.3683280944824219\n",
      "epoch :  407 , lrnCor :  854 valCor :  223 elapsed time :  0.36930012702941895\n",
      "epoch :  408 , lrnCor :  854 valCor :  223 elapsed time :  0.5277519226074219\n",
      "epoch :  409 , lrnCor :  854 valCor :  223 elapsed time :  0.6246199607849121\n",
      "epoch :  410 , lrnCor :  854 valCor :  223 elapsed time :  0.3747751712799072\n",
      "epoch :  411 , lrnCor :  854 valCor :  223 elapsed time :  0.41652393341064453\n",
      "epoch :  412 , lrnCor :  854 valCor :  223 elapsed time :  0.38269686698913574\n",
      "epoch :  413 , lrnCor :  854 valCor :  223 elapsed time :  0.37566089630126953\n",
      "epoch :  414 , lrnCor :  854 valCor :  223 elapsed time :  0.3982868194580078\n",
      "epoch :  415 , lrnCor :  854 valCor :  223 elapsed time :  0.3765099048614502\n",
      "epoch :  416 , lrnCor :  854 valCor :  223 elapsed time :  0.37734174728393555\n",
      "epoch :  417 , lrnCor :  855 valCor :  223 elapsed time :  0.37397003173828125\n",
      "epoch :  418 , lrnCor :  855 valCor :  223 elapsed time :  0.37087011337280273\n",
      "epoch :  419 , lrnCor :  855 valCor :  223 elapsed time :  0.372455358505249\n",
      "epoch :  420 , lrnCor :  856 valCor :  223 elapsed time :  0.38088083267211914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  421 , lrnCor :  856 valCor :  223 elapsed time :  0.3773989677429199\n",
      "epoch :  422 , lrnCor :  856 valCor :  223 elapsed time :  0.3664240837097168\n",
      "epoch :  423 , lrnCor :  856 valCor :  223 elapsed time :  0.3773331642150879\n",
      "epoch :  424 , lrnCor :  856 valCor :  223 elapsed time :  0.3672950267791748\n",
      "epoch :  425 , lrnCor :  857 valCor :  223 elapsed time :  0.3672018051147461\n",
      "epoch :  426 , lrnCor :  857 valCor :  223 elapsed time :  0.5978350639343262\n",
      "epoch :  427 , lrnCor :  857 valCor :  223 elapsed time :  0.3945028781890869\n",
      "epoch :  428 , lrnCor :  857 valCor :  223 elapsed time :  0.6398851871490479\n",
      "epoch :  429 , lrnCor :  858 valCor :  223 elapsed time :  0.36815404891967773\n",
      "epoch :  430 , lrnCor :  859 valCor :  223 elapsed time :  0.40974998474121094\n",
      "epoch :  431 , lrnCor :  860 valCor :  223 elapsed time :  0.664715051651001\n",
      "epoch :  432 , lrnCor :  860 valCor :  223 elapsed time :  0.37564802169799805\n",
      "epoch :  433 , lrnCor :  860 valCor :  223 elapsed time :  0.4084658622741699\n",
      "epoch :  434 , lrnCor :  860 valCor :  223 elapsed time :  0.36446690559387207\n",
      "epoch :  435 , lrnCor :  860 valCor :  223 elapsed time :  0.36900997161865234\n",
      "epoch :  436 , lrnCor :  860 valCor :  223 elapsed time :  0.369232177734375\n",
      "epoch :  437 , lrnCor :  860 valCor :  223 elapsed time :  0.38427114486694336\n",
      "epoch :  438 , lrnCor :  861 valCor :  223 elapsed time :  0.3709409236907959\n",
      "epoch :  439 , lrnCor :  861 valCor :  223 elapsed time :  0.6882929801940918\n",
      "epoch :  440 , lrnCor :  861 valCor :  223 elapsed time :  0.39944911003112793\n",
      "epoch :  441 , lrnCor :  861 valCor :  223 elapsed time :  0.4151186943054199\n",
      "epoch :  442 , lrnCor :  861 valCor :  223 elapsed time :  0.36922121047973633\n",
      "epoch :  443 , lrnCor :  861 valCor :  223 elapsed time :  0.3714640140533447\n",
      "epoch :  444 , lrnCor :  861 valCor :  223 elapsed time :  0.3704040050506592\n",
      "epoch :  445 , lrnCor :  862 valCor :  223 elapsed time :  0.36699795722961426\n",
      "epoch :  446 , lrnCor :  862 valCor :  223 elapsed time :  0.36976122856140137\n",
      "epoch :  447 , lrnCor :  862 valCor :  223 elapsed time :  0.3743419647216797\n",
      "epoch :  448 , lrnCor :  862 valCor :  223 elapsed time :  0.3729360103607178\n",
      "epoch :  449 , lrnCor :  862 valCor :  223 elapsed time :  0.3691420555114746\n",
      "epoch :  450 , lrnCor :  862 valCor :  223 elapsed time :  0.36660099029541016\n",
      "epoch :  451 , lrnCor :  862 valCor :  223 elapsed time :  0.36968183517456055\n",
      "epoch :  452 , lrnCor :  862 valCor :  223 elapsed time :  0.6855919361114502\n",
      "epoch :  453 , lrnCor :  862 valCor :  223 elapsed time :  0.5538349151611328\n",
      "epoch :  454 , lrnCor :  862 valCor :  223 elapsed time :  0.562065839767456\n",
      "epoch :  455 , lrnCor :  862 valCor :  223 elapsed time :  0.4045748710632324\n",
      "epoch :  456 , lrnCor :  862 valCor :  223 elapsed time :  0.3832418918609619\n",
      "epoch :  457 , lrnCor :  862 valCor :  223 elapsed time :  0.3750121593475342\n",
      "epoch :  458 , lrnCor :  862 valCor :  223 elapsed time :  0.4032402038574219\n",
      "epoch :  459 , lrnCor :  863 valCor :  223 elapsed time :  0.37830400466918945\n",
      "epoch :  460 , lrnCor :  863 valCor :  223 elapsed time :  0.36986684799194336\n",
      "epoch :  461 , lrnCor :  863 valCor :  223 elapsed time :  0.3718836307525635\n",
      "epoch :  462 , lrnCor :  863 valCor :  223 elapsed time :  0.3696310520172119\n",
      "epoch :  463 , lrnCor :  863 valCor :  223 elapsed time :  0.37132906913757324\n",
      "epoch :  464 , lrnCor :  863 valCor :  223 elapsed time :  0.3725159168243408\n",
      "epoch :  465 , lrnCor :  863 valCor :  223 elapsed time :  0.3831760883331299\n",
      "epoch :  466 , lrnCor :  863 valCor :  223 elapsed time :  0.4432399272918701\n",
      "epoch :  467 , lrnCor :  863 valCor :  223 elapsed time :  0.37111401557922363\n",
      "epoch :  468 , lrnCor :  863 valCor :  223 elapsed time :  0.4121429920196533\n",
      "epoch :  469 , lrnCor :  864 valCor :  223 elapsed time :  0.37723803520202637\n",
      "epoch :  470 , lrnCor :  864 valCor :  223 elapsed time :  0.5213696956634521\n",
      "epoch :  471 , lrnCor :  864 valCor :  223 elapsed time :  0.4352841377258301\n",
      "epoch :  472 , lrnCor :  864 valCor :  223 elapsed time :  0.42774105072021484\n",
      "epoch :  473 , lrnCor :  864 valCor :  223 elapsed time :  0.43801021575927734\n",
      "epoch :  474 , lrnCor :  864 valCor :  223 elapsed time :  0.4612088203430176\n",
      "epoch :  475 , lrnCor :  864 valCor :  223 elapsed time :  0.5055160522460938\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Initialize Coef to Zeros\n",
    "coef = np.zeros((1,10001), dtype = float)\n",
    "\n",
    "#Set Learning Rate\n",
    "lrnRate = 0.002\n",
    "\n",
    "# Set Loss Lists\n",
    "lrnLoss = list()\n",
    "valLoss = list()\n",
    "\n",
    "# Set Accurate Lists\n",
    "lrnAcc = list()\n",
    "valAcc = list()\n",
    "\n",
    "# set Elapsed time Lists\n",
    "elapTime = list()\n",
    "\n",
    "\n",
    "epoch = -1\n",
    "lrnAccRate = 0\n",
    "while(lrnAccRate < 0.85):\n",
    "    epoch += 1\n",
    "    # load training images of the batch size for every iteration\n",
    "    \n",
    "    #Set Sum of Derivatives to 0\n",
    "    sumDCoef = np.zeros((10001,1), dtype = float)\n",
    "    \n",
    "    #Set Sum of Loss to 0\n",
    "    sumL = 0\n",
    "    \n",
    "    #Set Sum of Cor to 0\n",
    "    cor = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for i, batMat in enumerate(trainList):\n",
    "        \n",
    "        batch_size = batMat.shape[1]\n",
    "\n",
    "\n",
    "        # Start Regression Calculation\n",
    "        z = np.dot(coef, batMat)                                           #coef.shape = (1,10001), batMat.shape = (10001, batch_size), z.shape = (1, batch_size)\n",
    "        a = 1/(1 + np.exp(-z))                                                 #a.shape = (1, batch_size)\n",
    "        dz = np.subtract(a, trainLabelList[i])                                        #dz.shape = (1, batch_size)\n",
    "        batMat = torch.from_numpy(batMat)                       #change ndarray to tensor\n",
    "        dCoef = dz * batMat                                                 #dCoef.shape = (10001, batch_size)\n",
    "        sumHelper = np.ones((batch_size,1), dtype = int)    #sumHelper.shape = (batch_size,1)\n",
    "        sumDCoef += np.dot(dCoef, sumHelper)                 #sumDCoef.shape = (10001, 1)\n",
    "        \n",
    "        \n",
    "        # Calculate Total Loss\n",
    "        a = torch.from_numpy(a)                       #change ndarray to tensor\n",
    "        dLabels = trainLabelList[i].double()                      #change tensor type to double\n",
    "        L = -(dLabels) * np.log(a) - (1-dLabels) * np.log(1-a)      #labels.shape = (1, batch_size), L.shape = (1,batch_size)\n",
    "        sumL += L.sum()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Calculate Accuracy\n",
    "        \n",
    "\n",
    "        for batIdx in range(batch_size):\n",
    "\n",
    "            if(a[0][batIdx] <= 0.5 and trainLabelList[i][batIdx] == 0):\n",
    "                cor += 1\n",
    "\n",
    "            if(a[0][batIdx] > 0.5 and trainLabelList[i][batIdx] == 1):\n",
    "                cor += 1\n",
    "            \n",
    "        \n",
    "    \n",
    "    totalDataNum = len(trainloader.dataset)\n",
    "        \n",
    "    # Calculate dLossdCoef\n",
    "\n",
    "    sumDCoef /= totalDataNum\n",
    "\n",
    "    # Update coefs using derivatives\n",
    "    coef = coef.T\n",
    "    coef -= lrnRate * sumDCoef\n",
    "    coef = coef.T\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    elapTime.append(elapsed_time)\n",
    "\n",
    "\n",
    "    # Calculate TotalLoss\n",
    "    sumL /= totalDataNum\n",
    "\n",
    "    lrnLoss.append(sumL)\n",
    "    \n",
    "    \n",
    "    # Calculate Accuracy\n",
    "    \n",
    "    lrnAccRate = cor/totalDataNum\n",
    "    lrnAcc.append(lrnAccRate)\n",
    "    \n",
    "                \n",
    "\n",
    "\n",
    "    # Set Sum Of Valid Loss to 0\n",
    "    sumVL = 0\n",
    "    # Set Sum of Valid Cor to 0\n",
    "    vCor = 0\n",
    "    \n",
    "    # load validation images of the batch size for every iteration\n",
    "    for i, batMat in enumerate(validList):\n",
    "        \n",
    "        \n",
    "        batch_size = batMat.shape[1]\n",
    "        \n",
    "        # Start Calculate Loss \n",
    "        z = np.dot(coef, batMat)\n",
    "        a = 1/(1+np.exp(-z))\n",
    "        a = torch.from_numpy(a)\n",
    "        dLabels = validLabelList[i].double()\n",
    "        L = -(dLabels) * np.log(a) - (1-dLabels) * np.log(1-a)\n",
    "        sumVL += L.sum()\n",
    "\n",
    "        \n",
    "        # Calculate Accuracy\n",
    "        \n",
    "        for batIdx in range(batch_size):\n",
    "            if(a[0][batIdx] <= 0.5 and validLabelList[i][batIdx] == 0):\n",
    "                vCor += 1\n",
    "                \n",
    "            if(a[0][batIdx] > 0.5 and validLabelList[i][batIdx] == 1):\n",
    "                vCor += 1\n",
    "    \n",
    "    totalValDataNum = len(valloader.dataset)\n",
    "    \n",
    "    # CalCulate Total Loss\n",
    "    sumVL /= totalValDataNum\n",
    "    valLoss.append(sumVL)\n",
    "    \n",
    "    \n",
    "    # Calculate Accuracy\n",
    "    vAcc = vCor/totalValDataNum\n",
    "    valAcc.append(vAcc)\n",
    "    \n",
    "    \n",
    "    print(\"epoch : \",epoch,',', \"lrnCor : \", cor, \"valCor : \", vCor, \"elapsed time : \", elapsed_time)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(elapTime, color = 'black', label = \"ElapsedTime\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"time\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plotting Loss\n",
    "\n",
    "fig, axs = plt.subplots(2,1, figsize = (10,4))\n",
    "\n",
    "\n",
    "axs[0].plot(lrnLoss, color = 'red', label = \"TrainingLoss\")\n",
    "\n",
    "\n",
    "axs[1].plot(valLoss, color = 'blue', label = \"ValidationLoss\")\n",
    "\n",
    "axs[0].set(ylabel = 'Loss')\n",
    "axs[1].set(xlabel = 'Iteration', ylabel = 'Loss')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Accuracy\n",
    "fig, axs = plt.subplots(2,1, figsize = (10,5))\n",
    "\n",
    "\n",
    "axs[0].plot(lrnAcc, color = 'orange', label = \"TrainingAccuracy\")\n",
    "\n",
    "\n",
    "axs[1].plot(valAcc, color = 'green', label = \"ValidationAccuracy\")\n",
    "\n",
    "axs[0].set(ylabel = 'Accuracy')\n",
    "axs[1].set(xlabel = 'Iteration', ylabel = 'Accuracy')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Altogether\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.title('Altogether')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.plot(lrnLoss, color = 'red', label = 'TrainingLoss')\n",
    "plt.plot(valLoss, color = 'blue', label = \"ValidationLoss\")\n",
    "plt.plot(lrnAcc, color = 'orange', label = \"TrainingAccuracy\")\n",
    "plt.plot(valAcc, color = 'green', label = \"ValidationAccuracy\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"  Dataset   |   Loss   | Accuracy\")\n",
    "\n",
    "print(\"  Training  | %.4f | %.4f\" % (lrnLoss[-1], lrnAcc[-1]))\n",
    "print(\" Validation| %.4f | %.4f\" % (valLoss[-1], valAcc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
