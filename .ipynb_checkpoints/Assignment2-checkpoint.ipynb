{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0 , cor :  500\n",
      "epoch :  1 , cor :  527\n",
      "epoch :  2 , cor :  529\n",
      "epoch :  3 , cor :  529\n",
      "epoch :  4 , cor :  555\n",
      "epoch :  5 , cor :  562\n",
      "epoch :  6 , cor :  569\n",
      "epoch :  7 , cor :  577\n",
      "epoch :  8 , cor :  577\n",
      "epoch :  9 , cor :  584\n",
      "epoch :  10 , cor :  602\n",
      "epoch :  11 , cor :  626\n",
      "epoch :  12 , cor :  638\n",
      "epoch :  13 , cor :  650\n",
      "epoch :  14 , cor :  663\n",
      "epoch :  15 , cor :  671\n",
      "epoch :  16 , cor :  677\n",
      "epoch :  17 , cor :  684\n",
      "epoch :  18 , cor :  687\n",
      "epoch :  19 , cor :  690\n",
      "epoch :  20 , cor :  699\n",
      "epoch :  21 , cor :  702\n",
      "epoch :  22 , cor :  707\n",
      "epoch :  23 , cor :  710\n",
      "epoch :  24 , cor :  713\n",
      "epoch :  25 , cor :  716\n",
      "epoch :  26 , cor :  723\n",
      "epoch :  27 , cor :  726\n",
      "epoch :  28 , cor :  724\n",
      "epoch :  29 , cor :  726\n",
      "epoch :  30 , cor :  731\n",
      "epoch :  31 , cor :  733\n",
      "epoch :  32 , cor :  733\n",
      "epoch :  33 , cor :  732\n",
      "epoch :  34 , cor :  733\n",
      "epoch :  35 , cor :  737\n",
      "epoch :  36 , cor :  739\n",
      "epoch :  37 , cor :  742\n",
      "epoch :  38 , cor :  744\n",
      "epoch :  39 , cor :  745\n",
      "epoch :  40 , cor :  746\n",
      "epoch :  41 , cor :  748\n",
      "epoch :  42 , cor :  751\n",
      "epoch :  43 , cor :  752\n",
      "epoch :  44 , cor :  751\n",
      "epoch :  45 , cor :  751\n",
      "epoch :  46 , cor :  751\n",
      "epoch :  47 , cor :  752\n",
      "epoch :  48 , cor :  754\n",
      "epoch :  49 , cor :  758\n",
      "epoch :  50 , cor :  758\n",
      "epoch :  51 , cor :  758\n",
      "epoch :  52 , cor :  759\n",
      "epoch :  53 , cor :  762\n",
      "epoch :  54 , cor :  764\n",
      "epoch :  55 , cor :  765\n",
      "epoch :  56 , cor :  764\n",
      "epoch :  57 , cor :  766\n",
      "epoch :  58 , cor :  767\n",
      "epoch :  59 , cor :  768\n",
      "epoch :  60 , cor :  769\n",
      "epoch :  61 , cor :  770\n",
      "epoch :  62 , cor :  772\n",
      "epoch :  63 , cor :  773\n",
      "epoch :  64 , cor :  773\n",
      "epoch :  65 , cor :  774\n",
      "epoch :  66 , cor :  774\n",
      "epoch :  67 , cor :  775\n",
      "epoch :  68 , cor :  775\n",
      "epoch :  69 , cor :  776\n",
      "epoch :  70 , cor :  776\n",
      "epoch :  71 , cor :  777\n",
      "epoch :  72 , cor :  778\n",
      "epoch :  73 , cor :  778\n",
      "epoch :  74 , cor :  780\n",
      "epoch :  75 , cor :  781\n",
      "epoch :  76 , cor :  781\n",
      "epoch :  77 , cor :  781\n",
      "epoch :  78 , cor :  782\n",
      "epoch :  79 , cor :  782\n",
      "epoch :  80 , cor :  782\n",
      "epoch :  81 , cor :  783\n",
      "epoch :  82 , cor :  783\n",
      "epoch :  83 , cor :  784\n",
      "epoch :  84 , cor :  784\n",
      "epoch :  85 , cor :  785\n",
      "epoch :  86 , cor :  785\n",
      "epoch :  87 , cor :  785\n",
      "epoch :  88 , cor :  785\n",
      "epoch :  89 , cor :  784\n",
      "epoch :  90 , cor :  784\n",
      "epoch :  91 , cor :  785\n",
      "epoch :  92 , cor :  785\n",
      "epoch :  93 , cor :  785\n",
      "epoch :  94 , cor :  785\n",
      "epoch :  95 , cor :  785\n",
      "epoch :  96 , cor :  786\n",
      "epoch :  97 , cor :  785\n",
      "epoch :  98 , cor :  785\n",
      "epoch :  99 , cor :  785\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = './horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=3, shuffle=False, num_workers=1)  \n",
    "\n",
    "\n",
    "validation_data_path = './horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=3, shuffle=False, num_workers=1)  \n",
    "\n",
    "NUM_EPOCH = 100\n",
    "\n",
    "\n",
    "\n",
    "#Initialize Coef to Zeros\n",
    "coef = np.zeros((1,10001), dtype = float)\n",
    "\n",
    "#Set Learning Rate\n",
    "lrnRate = 0.002\n",
    "\n",
    "# Set Loss Lists\n",
    "lrnLoss = list()\n",
    "\n",
    "# Set Accurate Lists\n",
    "lrnAcc = list()\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    # load training images of the batch size for every iteration\n",
    "    \n",
    "    #Set Sum of Derivatives to 0\n",
    "    sumDCoef = np.zeros((10001,1), dtype = float)\n",
    "    \n",
    "    #Set Sum of Loss to 0\n",
    "    sumL = 0\n",
    "    \n",
    "    #Set Sum of Cor to 0\n",
    "    cor = 0\n",
    "    \n",
    "    for i, data in enumerate(trainloader):\n",
    "        # inputs is the image\n",
    "        # labels is the class of the image\n",
    "        inputs, labels = data\n",
    "        \n",
    "\n",
    "        # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "        batch_size = inputs.shape[0]\n",
    "\n",
    "\n",
    "        # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "\n",
    "        \n",
    "        # change inputs to matrix 10000*batch_size\n",
    "        for bat_idx in range(batch_size):\n",
    "            \n",
    "            targMat = inputs[bat_idx][0]\n",
    "            colVec = np.reshape(targMat, (np.product(targMat.shape), 1), 'F')\n",
    "            \n",
    "            if(bat_idx == 0):\n",
    "                batMat = colVec\n",
    "            else:\n",
    "                batMat = np.concatenate((batMat, colVec), axis = 1)         \n",
    "        # Add ones because of the value b in coefficient\n",
    "        ones = np.ones((1, batch_size), dtype = int)\n",
    "        batMat = np.concatenate((batMat, ones))\n",
    "        \n",
    "\n",
    "        \n",
    "        # Start Regression Calculation\n",
    "        z = np.dot(coef, batMat)                                           #coef.shape = (1,10001), batMat.shape = (10001, batch_size), z.shape = (1, batch_size)\n",
    "        a = 1/(1 + np.exp(-z))                                                 #a.shape = (1, batch_size)\n",
    "        dz = np.subtract(a, labels)                                        #dz.shape = (1, batch_size)\n",
    "        batMat = torch.from_numpy(batMat)                       #change ndarray to tensor\n",
    "        dCoef = dz * batMat                                                 #dCoef.shape = (10001, batch_size)\n",
    "        sumHelper = np.ones((batch_size,1), dtype = int)    #sumHelper.shape = (batch_size,1)\n",
    "        sumDCoef += np.dot(dCoef, sumHelper)                 #sumDCoef.shape = (10001, batch_size)\n",
    "        \n",
    "        \n",
    "        # Calculate Total Loss\n",
    "        a = torch.from_numpy(a)                       #change ndarray to tensor\n",
    "        dLabels = labels.double()                      #change tensor type to double\n",
    "        L = -(dLabels) * np.log(a) - (1-dLabels) * np.log(1-a)      #labels.shape = (1, batch_size), L.shape = (1,batch_size)\n",
    "        sumL += L.sum()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Calculate Accuracy\n",
    "        \n",
    "\n",
    "        for batIdx in range(batch_size):\n",
    "\n",
    "            if(a[0][batIdx] <= 0.5 and labels[batIdx] == 0):\n",
    "                cor += 1\n",
    "\n",
    "            if(a[0][batIdx] > 0.5 and labels[batIdx] == 1):\n",
    "                cor += 1\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "    totalDataNum = len(trainloader.dataset)\n",
    "        \n",
    "    # Calculate dLossdCoef\n",
    "\n",
    "    sumDCoef /= totalDataNum\n",
    "\n",
    "    # Update coefs using derivatives\n",
    "    coef = coef.T\n",
    "    coef -= lrnRate * sumDCoef\n",
    "    coef = coef.T\n",
    "\n",
    "    # Calculate TotalLoss\n",
    "    sumL /= totalDataNum\n",
    "\n",
    "    lrnLoss.append(sumL)\n",
    "    \n",
    "    \n",
    "    # Calculate Accuracy\n",
    "    print(\"epoch : \",epoch,',', \"cor : \",cor)\n",
    "    cor /= totalDataNum\n",
    "    lrnAcc.append(cor)\n",
    "    \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "    # load validation images of the batch size for every iteration\n",
    "    for i, data in enumerate(valloader):\n",
    "        \n",
    "        # inputs is the image\n",
    "        # labels is the class of the image\n",
    "        inputs, labels = data\n",
    "\n",
    "        # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "        #print(inputs.shape)\n",
    "\n",
    "        # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "        #print(labels)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(lrnLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lrnAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
